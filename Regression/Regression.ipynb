{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1 >> What is Simple Linear Regression?\n",
    "\n",
    "Ans >> Simple Linear Regression is a statistical method used to model the relationship between a dependent variable (Y) and one independent variable (X) using a straight line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2 >> What are the key assumptions of Simple Linear Regression?\n",
    "\n",
    "Ans >> \n",
    "Linearity: The relationship between X and Y is linear.\n",
    "\n",
    "Independence: Observations are independent of each other.\n",
    "\n",
    "Homoscedasticity: Constant variance of residuals across all levels of X.\n",
    "\n",
    "Normality: Residuals are normally distributed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3 >> What does the coefficient m represent in the equation Y = mX + c ?\n",
    "\n",
    "Ans >> m  represents the slope of the line, indicating the rate of change in Y for a unit change in X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4 >> What does the intercept c represent in the equation Y = mX+c?\n",
    "\n",
    "Ans >> c  represents the value of Y when X is 0. It is the point where the line intersects the Y-axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5 >> How do we calculate the slope m in Simple Linear Regression?\n",
    "\n",
    "Ans >> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 >> What is the purpose of the least squares method in Simple Linear Regression?\n",
    "\n",
    "Ans >> The least squares method minimizes the sum of squared residuals (differences between observed and predicted values) to find the best-fitting line.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7 >> How is the coefficient of determination (R^2) interpreted in Simple Linear Regression?\n",
    "\n",
    "Ans>> (R^2) represents the proportion of variance in the dependent variable (Y) explained by the independent variable (X)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8 >> What is Multiple Linear Regression?\n",
    "\n",
    "Ans>> Multiple Linear Regression is a statistical method used to model the relationship between a dependent variable (Y) and two or more independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9>>What is the main difference between Simple and Multiple Linear Regression?\n",
    "\n",
    "Ans>> Simple Linear Regression uses one independent variable, while Multiple Linear Regression uses multiple independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10>>What are the key assumptions of Multiple Linear Regression?\n",
    "\n",
    "Ans>>\n",
    "\n",
    "Linearity: Linear relationship between predictors and the dependent variable.\n",
    "\n",
    "Independence of errors.\n",
    "\n",
    "Homoscedasticity of residuals.\n",
    "\n",
    "No multicollinearity among independent variables.\n",
    "\n",
    "Normal distribution of residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q11>>What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
    "\n",
    "Ans>>Heteroscedasticity occurs when residuals have non-constant variance. It can lead to inefficient estimates and affect hypothesis testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q12>>How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
    "\n",
    "Ans>>\n",
    "\n",
    "Remove highly correlated variables.\n",
    "\n",
    "Use regularization techniques like Ridge or Lasso regression.\n",
    "\n",
    "Combine correlated predictors using techniques like PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q13>>What are some common techniques for transforming categorical variables for use in regression models?\n",
    "\n",
    "\n",
    "Ans>>\n",
    "\n",
    "One-hot encoding.\n",
    "\n",
    "Label encoding.\n",
    "\n",
    "Dummy variable creation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q14>>What is the role of interaction terms in Multiple Linear Regression?\n",
    "\n",
    "Ans>>Interaction terms capture the combined effect of two or more predictors on the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q15>>How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
    "\n",
    "Ans>>In Multiple Linear Regression, the intercept represents the predicted value of Y when all independent variables are 0, which may not always have practical meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q16>>What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
    "\n",
    "Ans>>The slope indicates the effect of an independent variable on the dependent variable. It helps in understanding the relationship and making predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q17>>How does the intercept in a regression model provide context for the relationship between variables?\n",
    "Ans>>It provides a baseline value for the dependent variable when all predictors are zero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q18>>What are the limitations of using R^2 as a sole measure of model performance?\n",
    "\n",
    "Ans>>\n",
    "It does not indicate if the model is biased.\n",
    "\n",
    "\n",
    "It cannot determine causation.\n",
    "\n",
    "Adding predictors always increases R^2 , even if they are not significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q19>>How would you interpret a large standard error for a regression coefficient?\n",
    "\n",
    "Ans>>A large standard error indicates that the coefficient estimate is imprecise and may not significantly contribute to the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q20>>How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
    "\n",
    "It can be identified when the spread of residuals varies across levels of the independent variable(s). Addressing it ensures valid inferences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q21>>What does it mean if a Multiple Linear Regression model has a high R^2 but low adjusted R^2 ?\n",
    "\n",
    "Ans>>It suggests that unnecessary predictors are inflating R^2, and the model may be overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q22 >> Why is it important to scale variables in Multiple Linear Regression?\n",
    "\n",
    "Ans>>Scaling ensures that variables with larger ranges do not dominate the regression coefficients and improves convergence in optimization algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q23 >>What is Polynomial Regression?\n",
    "\n",
    "Ans>>Polynomial Regression models the relationship between a dependent variable and an independent variable as an nth-degree polynomial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q24 >> How does polynomial regression differ from linear regression?\n",
    "\n",
    "Ans>>Polynomial regression can model nonlinear relationships, while linear regression assumes a straight-line relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q25 >> When is polynomial regression used?\n",
    "Ans>> It is used when the data shows a curvilinear pattern that cannot be captured by a straight line.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q26>>What is the general equation for polynomial regression?\n",
    "\n",
    "Ans>> Y = b0 + b1X + b2X^2 + ..... + bnX^n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q27 >> Can polynomial regression be applied to multiple variables?\n",
    "\n",
    "Ans>>Yes, it can be extended to include multiple predictors with polynomial terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q28>>What are the limitations of polynomial regression?\n",
    "\n",
    "Ans>>\n",
    "\n",
    "Risk of overfitting for high-degree polynomials.\n",
    "\n",
    "Computationally expensive for large datasets.\n",
    "\n",
    "Sensitive to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q29>>What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
    "\n",
    "\n",
    "Cross-validation.\n",
    "\n",
    "Analyzing residual plots.\n",
    "\n",
    "Using metrics like R^2 and Adjusted R^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q30>>Why is visualization important in polynomial regression?\n",
    "Visualization helps in understanding the fit of the model and identifying overfitting or underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q30>>How is polynomial regression implemented in Python?\n",
    "\n",
    "Ans>> It can be implemented using libraries like scikit-learn:"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
